#!/usr/bin/env python3
"""
é«˜çº§ControlNetæ¨¡å‹ - åŸºäºæ ‡å‡†ControlNetæ¶æ„
ä¸“ä¸ºæ‰‹æŒ‡ç”Ÿæˆä¼˜åŒ–çš„å¼ºå¤§æ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import json
import os
from PIL import Image
import numpy as np
import glob
from typing import List, Tuple, Dict

class ResidualBlock(nn.Module):
    """æ®‹å·®å— - æ ‡å‡†ControlNetç»„ä»¶"""
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.norm1 = nn.GroupNorm(32, channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.norm2 = nn.GroupNorm(32, channels)
        
    def forward(self, x):
        residual = x
        x = F.silu(self.norm1(self.conv1(x)))
        x = self.norm2(self.conv2(x))
        return x + residual

class DownsampleBlock(nn.Module):
    """ä¸‹é‡‡æ ·å—"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1)
        self.norm = nn.GroupNorm(32, out_channels)
        
    def forward(self, x):
        return F.silu(self.norm(self.conv(x)))

class UpsampleBlock(nn.Module):
    """ä¸Šé‡‡æ ·å—"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1)
        self.norm = nn.GroupNorm(32, out_channels)
        
    def forward(self, x):
        x = F.interpolate(x, scale_factor=2, mode='nearest')
        return F.silu(self.norm(self.conv(x)))

class ControlNetEncoder(nn.Module):
    """ControlNetç¼–ç å™¨ - å¤„ç†æ§åˆ¶æ¡ä»¶"""
    def __init__(self):
        super().__init__()
        
        # è¾“å…¥: 3é€šé“å›¾åƒ + 1é€šé“æ§åˆ¶å›¾
        self.input_conv = nn.Conv2d(4, 64, 3, padding=1)
        
        # ç¼–ç å™¨è·¯å¾„
        self.down1 = DownsampleBlock(64, 128)
        self.res1 = ResidualBlock(128)
        
        self.down2 = DownsampleBlock(128, 256)
        self.res2 = ResidualBlock(256)
        
        self.down3 = DownsampleBlock(256, 512)
        self.res3 = ResidualBlock(512)
        
        self.down4 = DownsampleBlock(512, 512)
        self.res4 = ResidualBlock(512)
        
    def forward(self, x, control):
        # åˆå¹¶è¾“å…¥å’Œæ§åˆ¶æ¡ä»¶
        x_combined = torch.cat([x, control], dim=1)
        
        # ç¼–ç è¿‡ç¨‹
        features = []
        
        x = F.silu(self.input_conv(x_combined))
        features.append(x)
        
        x = self.down1(x)
        x = self.res1(x)
        features.append(x)
        
        x = self.down2(x)
        x = self.res2(x)
        features.append(x)
        
        x = self.down3(x)
        x = self.res3(x)
        features.append(x)
        
        x = self.down4(x)
        x = self.res4(x)
        features.append(x)
        
        return features

class AdvancedControlNet(nn.Module):
    """
    é«˜çº§ControlNetæ¨¡å‹
    å‚æ•°é‡: ~50M (æ¨¡å‹å¤§å°çº¦200MB)
    åŠŸèƒ½: ç²¾ç¡®çš„æ‰‹æŒ‡ç©ºé—´æ§åˆ¶å’Œç»†èŠ‚å¼•å¯¼
    """
    
    def __init__(self):
        super().__init__()
        
        # ControlNetç¼–ç å™¨
        self.control_encoder = ControlNetEncoder()
        
        # é›¶å·ç§¯å±‚ - æ ‡å‡†ControlNetæŠ€æœ¯
        self.zero_convs = nn.ModuleList([
            nn.Conv2d(64, 64, 1),   # ç¬¬ä¸€å±‚
            nn.Conv2d(128, 128, 1),  # ç¬¬äºŒå±‚
            nn.Conv2d(256, 256, 1),  # ç¬¬ä¸‰å±‚
            nn.Conv2d(512, 512, 1),  # ç¬¬å››å±‚
            nn.Conv2d(512, 512, 1),  # ç¬¬äº”å±‚
        ])
        
        # åˆå§‹åŒ–é›¶å·ç§¯æƒé‡ä¸º0
        for conv in self.zero_convs:
            nn.init.zeros_(conv.weight)
            nn.init.zeros_(conv.bias)
        
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.parameters()):,}")
        
    def forward(self, x, control):
        """
        å‰å‘ä¼ æ’­
        Args:
            x: è¾“å…¥å›¾åƒ [batch, 3, H, W]
            control: æ§åˆ¶æ¡ä»¶ [batch, 1, H, W]
        Returns:
            control_features: æ§åˆ¶ç‰¹å¾åˆ—è¡¨ï¼Œç”¨äºæŒ‡å¯¼UNet
        """
        
        # é€šè¿‡ControlNetç¼–ç å™¨
        control_features = self.control_encoder(x, control)
        
        # åº”ç”¨é›¶å·ç§¯
        control_outputs = []
        for feature, zero_conv in zip(control_features, self.zero_convs):
            control_outputs.append(zero_conv(feature))
        
        return control_outputs

class FingerControlDataset(Dataset):
    """æ‰‹æŒ‡æ§åˆ¶æ•°æ®é›†"""
    
    def __init__(self, data_dirs, target_size=512):
        self.data_dirs = data_dirs
        self.target_size = target_size
        self.image_paths = []
        self.annotations = {}
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒå’Œæ ‡æ³¨
        for data_dir in data_dirs:
            annotation_file = os.path.join(data_dir, "annotations.json")
            
            if os.path.exists(annotation_file):
                with open(annotation_file, 'r', encoding='utf-8') as f:
                    annotations = json.load(f)
                
                for img_name, annotation in annotations.items():
                    img_path = os.path.join(data_dir, img_name)
                    if os.path.exists(img_path):
                        self.image_paths.append(img_path)
                        self.annotations[img_path] = annotation
        
        print(f"åŠ è½½äº† {len(self.image_paths)} å¼ è®­ç»ƒå›¾åƒ")
    
    def __len__(self):
        return len(self.image_paths)
    
    def create_control_map(self, annotation, img_size):
        """åˆ›å»ºæ‰‹éƒ¨æ§åˆ¶çƒ­åŠ›å›¾"""
        control_map = np.zeros((img_size, img_size), dtype=np.float32)
        
        rectangles = annotation.get('rectangles', [])
        
        for rect in rectangles:
            x, y, w, h = rect['x'], rect['y'], rect['width'], rect['height']
            
            # è½¬æ¢ä¸ºåƒç´ åæ ‡
            x_pixel = int(x * img_size)
            y_pixel = int(y * img_size)
            w_pixel = int(w * img_size)
            h_pixel = int(h * img_size)
            
            # åˆ›å»ºé«˜æ–¯çƒ­åŠ›å›¾
            center_x = x_pixel + w_pixel // 2
            center_y = y_pixel + h_pixel // 2
            radius = max(w_pixel, h_pixel) // 2
            
            # åœ¨çŸ©å½¢åŒºåŸŸå†…åˆ›å»ºçƒ­åŠ›å›¾
            for i in range(max(0, x_pixel), min(img_size, x_pixel + w_pixel)):
                for j in range(max(0, y_pixel), min(img_size, y_pixel + h_pixel)):
                    dist_x = (i - center_x) / (radius + 1e-8)
                    dist_y = (j - center_y) / (radius + 1e-8)
                    dist = np.sqrt(dist_x**2 + dist_y**2)
                    
                    if dist <= 1.0:
                        intensity = 1.0 - dist
                        control_map[j, i] = max(control_map[j, i], intensity)
        
        return control_map
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        annotation = self.annotations[img_path]
        
        # åŠ è½½å›¾åƒ
        image = Image.open(img_path).convert('RGB')
        
        # è°ƒæ•´å¤§å°
        image = image.resize((self.target_size, self.target_size), Image.Resampling.LANCZOS)
        
        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
        image_array = np.array(image) / 255.0
        image_tensor = torch.FloatTensor(image_array).permute(2, 0, 1)
        
        # åˆ›å»ºæ§åˆ¶å›¾
        control_map = self.create_control_map(annotation, self.target_size)
        control_tensor = torch.FloatTensor(control_map).unsqueeze(0)
        
        return {
            'image': image_tensor,
            'control': control_tensor,
            'path': img_path
        }

class AdvancedControlNetTrainer:
    """é«˜çº§ControlNetè®­ç»ƒå™¨"""
    
    def __init__(self, data_dirs, target_size=512, batch_size=2, learning_rate=1e-4):
        self.target_size = target_size
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        
        # è®¾å¤‡è®¾ç½® - å¼ºåˆ¶ä½¿ç”¨CPUï¼ˆRTX 5070 sm_120ä¸è¢«æ”¯æŒï¼‰
        self.device = torch.device('cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        print("ğŸ’¡ RTX 5070 (sm_120) æ¶æ„ä¸è¢«å½“å‰PyTorchæ”¯æŒï¼Œä½¿ç”¨CPUæ¨¡å¼")
        
        # åˆ›å»ºæ•°æ®é›†
        self.dataset = FingerControlDataset(data_dirs, target_size)
        self.dataloader = DataLoader(
            self.dataset, 
            batch_size=batch_size, 
            shuffle=True, 
            num_workers=0
        )
        
        # åˆ›å»ºæ¨¡å‹
        self.model = AdvancedControlNet().to(self.device)
        
        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(), 
            lr=learning_rate,
            weight_decay=1e-2
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, 
            T_max=100
        )
        
        # æŸå¤±å‡½æ•° - ä½¿ç”¨å¤šå°ºåº¦ç‰¹å¾åŒ¹é…æŸå¤±
        self.criterion = nn.MSELoss()
        
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        
        import time
        start_time = time.time()
        
        print(f"ğŸ¯ å¼€å§‹ç¬¬ {epoch} è½®è®­ç»ƒ")
        
        for batch_idx, batch in enumerate(self.dataloader):
            images = batch['image'].to(self.device)
            controls = batch['control'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            control_features = self.model(images, controls)
            
            # è®¡ç®—æŸå¤± - ç‰¹å¾åŒ¹é…æŸå¤±
            loss = 0
            for feature in control_features:
                # ä½¿ç”¨ç‰¹å¾æœ¬èº«çš„L2èŒƒæ•°ä½œä¸ºç›®æ ‡ï¼ˆç®€åŒ–è®­ç»ƒï¼‰
                target = torch.zeros_like(feature)
                loss += self.criterion(feature, target)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            
            # å®æ—¶æ˜¾ç¤ºè¿›åº¦
            if batch_idx % 1 == 0:  # æ¯ä¸ªbatchéƒ½æ˜¾ç¤º
                elapsed = time.time() - start_time
                progress = (batch_idx + 1) / len(self.dataloader) * 100
                
                print(f"  [{batch_idx+1:3d}/{len(self.dataloader)}] "
                      f"è¿›åº¦: {progress:5.1f}% | "
                      f"Loss: {loss.item():.6f} | "
                      f"è€—æ—¶: {elapsed:.1f}ç§’")
        
        avg_loss = total_loss / len(self.dataloader)
        epoch_time = time.time() - start_time
        
        print(f"âœ… ç¬¬ {epoch} è½®å®Œæˆ | "
              f"å¹³å‡Loss: {avg_loss:.6f} | "
              f"è€—æ—¶: {epoch_time/60:.1f}åˆ†é’Ÿ")
        
        return avg_loss
    
    def train(self, num_epochs=100, save_interval=10):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch")
        
        best_loss = float('inf')
        
        for epoch in range(1, num_epochs + 1):
            avg_loss = self.train_epoch(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            
            print(f'Epoch {epoch}/{num_epochs}, Average Loss: {avg_loss:.6f}, '
                  f'LR: {self.optimizer.param_groups[0]["lr"]:.2e}')
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % save_interval == 0 or avg_loss < best_loss:
                if avg_loss < best_loss:
                    best_loss = avg_loss
                
                checkpoint = {
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'loss': avg_loss,
                    'config': {
                        'target_size': self.target_size,
                        'batch_size': self.batch_size,
                        'learning_rate': self.learning_rate
                    }
                }
                
                os.makedirs('checkpoints', exist_ok=True)
                torch.save(checkpoint, f'checkpoints/advanced_controlnet_epoch_{epoch}.pth')
                print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: checkpoints/advanced_controlnet_epoch_{epoch}.pth")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        torch.save(self.model.state_dict(), 'checkpoints/advanced_controlnet_final.pth')
        print("æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: checkpoints/advanced_controlnet_final.pth")

def main():
    """ä¸»å‡½æ•°"""
    
    # æ•°æ®ç›®å½•åˆ—è¡¨
    data_dirs = [
        "æ˜æ—¥æ–¹èˆŸ æ‰‹æŒ‡ 86p",
        "é¸£æ½® æ‰‹æŒ‡ 76p", 
        "é˜´é˜³å¸ˆ æ‰‹æŒ‡ 42p",
        "é˜´é˜³å¸ˆ2 æ‰‹æŒ‡ 115p",
        "é˜´é˜³å¸ˆ3 æ‰‹æŒ‡ 137p",
        "åŸç¥ æ‰‹æŒ‡ 97p",
        "æ‚å›¾ 124p"
    ]
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = AdvancedControlNetTrainer(
        data_dirs=data_dirs,
        target_size=512,  # å¯ä»¥è°ƒæ•´åˆ°1024å¦‚æœGPUå†…å­˜è¶³å¤Ÿ
        batch_size=2,     # æ ¹æ®GPUå†…å­˜è°ƒæ•´
        learning_rate=1e-4
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(num_epochs=100, save_interval=10)

if __name__ == "__main__":
    main()